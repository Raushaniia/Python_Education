import osimport sysimport numpy as npimport tensorflow as tfimport randomimport mathimport warningsimport pandas as pdimport matplotlib.pyplot as pltimport cv2from tqdm import tqdm_notebook as tqdmfrom sklearn.model_selection import train_test_splitwarnings.filterwarnings('ignore', category=UserWarning, module='skimage')seed = 42random.seed = seednp.random.seed = seed# Set some parametersIMG_WIDTH = 576IMG_HEIGHT = 576MASK_WIDTH = 388MASK_HEIGHT = 388TRAIN_PATH = "data/"IMG_PATH = 'images1/'MASK_PATH = 'masks1/'train_images_names = [file for file in os.listdir(TRAIN_PATH+MASK_PATH) if '.png' in file or '.jpg' in file]images = np.zeros((len(train_images_names), IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.uint8)labels = np.zeros((len(train_images_names), MASK_HEIGHT, MASK_WIDTH, 1), dtype=np.bool)for idx, filename in tqdm(enumerate(train_images_names)):    img = cv2.imread(TRAIN_PATH + IMG_PATH + filename, 0)    plt.imshow(img)    if img is not None:        img = cv2.resize(img, (MASK_HEIGHT, MASK_WIDTH))    img_border = np.zeros((IMG_HEIGHT, IMG_WIDTH), dtype=np.uint8)    h_st = (IMG_HEIGHT - MASK_HEIGHT) // 2    h_fin = MASK_HEIGHT + h_st    w_st = (IMG_WIDTH - MASK_WIDTH) // 2    w_fin = MASK_WIDTH + w_st    img_border[h_st:h_fin, w_st:w_fin] = img    images[idx] = np.expand_dims(img_border, axis=2)    plt.imshow(img_border)    mask = cv2.imread(TRAIN_PATH + MASK_PATH + filename, 0)    mask_new = cv2.resize(mask, (MASK_HEIGHT, MASK_WIDTH))    plt.imshow(mask_new)    mask = np.expand_dims((mask_new), axis=2)    labels[idx] = mask.astype(np.bool)X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)def shuffle():    global X_train, y_train    p = np.random.permutation(len(X_train))    X_train = X_train[p]    y_train = y_train[p]def next_batch(batch_s, iters):    if(iters == 0):        shuffle()    count = batch_s * iters    return X_train[count:(count + batch_s)], y_train[count:(count + batch_s)]def preprocess_batch(batch_X):    batch_X_prep = (batch_X - 127.5) / 127.5    return batch_X_prepdef deconv2d(input_tensor, filter_size, output_size, out_channels, in_channels, name, strides = [1, 2, 2, 1]):    dyn_input_shape = tf.shape(input_tensor)    batch_size = dyn_input_shape[0]    out_shape = tf.stack([batch_size, output_size, output_size, out_channels])    filter_shape = [filter_size, filter_size, out_channels, in_channels]    w = tf.get_variable(name=name, shape=filter_shape)    h1 = tf.nn.conv2d_transpose(input_tensor, w, out_shape, strides, padding='SAME', name='conv_trans_'+name)    return h1def conv2d(input_tensor, depth, kernel, name, strides=(1, 1), padding="SAME", activation='relu'):    #tf.layers.batch_normalization(input_tensor, training=True)    if activation == 'relu':        tf_act = tf.nn.relu    elif activation == 'linear':        tf_act = None    return tf.layers.conv2d(input_tensor, filters=depth, kernel_size=kernel, strides=strides, padding=padding, activation=tf_act, name=name)def unet_upsample_layer(to_upsample_l, conv_toconcat_l, num_feat_maps, num_block):    out_size = to_upsample_l.shape[1]    inp_channels = to_upsample_l.shape[-1]    deconv_l = deconv2d(to_upsample_l, 2, out_size*2,num_feat_maps, inp_channels, 'dc_w_'+str(num_block)) #56    crop_h_1 = (tf.shape(conv_toconcat_l)[1] - tf.shape(deconv_l)[1]) // 2    crop_h_2 = tf.shape(deconv_l)[1] + crop_h_1    crop_w_1 = (tf.shape(conv_toconcat_l)[2] - tf.shape(deconv_l)[2]) // 2    crop_w_2 = tf.shape(deconv_l)[2] + crop_w_1    croped = conv_toconcat_l[:,crop_h_1:crop_h_2,crop_w_1:crop_w_2,:]    concat = tf.concat([deconv_l, croped], axis=3)    deconv_conv1 = conv2d(concat, num_feat_maps, 3, "conv_up"+str(num_block)+"_1", padding='VALID')    deconv_conv2 = conv2d(deconv_conv1, num_feat_maps, 3, "conv_up"+str(num_block)+"_2", padding='VALID')    return deconv_conv2tf.reset_default_graph()X = tf.placeholder(tf.float32, [None, 576, 576, 1])lr = tf.placeholder(tf.float32)conv1_1 = conv2d(X, 64, 3, "conv_1_1", padding='VALID') #570conv1_2 = conv2d(conv1_1, 64, 3, "conv_1_2", padding='VALID') #568max_pool_1  = tf.layers.max_pooling2d(conv1_2,(2,2),(2,2),padding='valid',name='max_pool_1') #284conv2_1 = conv2d(max_pool_1, 128, 3, "conv_2_1", padding='VALID') #282conv2_2 = conv2d(conv2_1, 128, 3, "conv_2_2", padding='VALID') #280max_pool_2  = tf.layers.max_pooling2d(conv2_2,(2,2),(2,2),padding='valid',name='max_pool_1') #140conv3_1 = conv2d(max_pool_2, 256, 3, "conv_3_1", padding='VALID') #138conv3_2 = conv2d(conv3_1, 256, 3, "conv_3_2", padding='VALID') #136max_pool_3  = tf.layers.max_pooling2d(conv3_2,(2,2),(2,2),padding='valid',name='max_pool_1') #68conv4_1 = conv2d(max_pool_3, 512, 3, "conv_4_1", padding='VALID') #66conv4_2 = conv2d(conv4_1, 512, 3, "conv_4_2", padding='VALID') #64max_pool_4  = tf.layers.max_pooling2d(conv4_2,(2,2),(2,2),padding='valid',name='max_pool_1') #32conv5_1 = conv2d(max_pool_4, 1024, 3, "conv_5_1", padding='VALID') #30conv5_2 = conv2d(conv5_1, 1024, 3, "conv_5_2", padding='VALID') #28deconv_block_4 = unet_upsample_layer(conv5_2, conv4_2, 512, 4) #52deconv_block_3 = unet_upsample_layer(deconv_block_4, conv3_2, 256, 3) #100deconv_block_2 = unet_upsample_layer(deconv_block_3, conv2_2, 128, 2) #196deconv_block_1 = unet_upsample_layer(deconv_block_2, conv1_2, 64, 1) #388logits = conv2d(deconv_block_1, 1, 1, "conv_last_1_1", padding='VALID', activation='linear')sigmoid = tf.sigmoid(logits)Y = tf.placeholder(tf.float32, [None, 388, 388, 1])loss = tf.losses.sigmoid_cross_entropy(Y, logits)# writer = tf.summary.FileWriter("./logs/", sess.graph)optimizer = tf.train.AdamOptimizer(lr).minimize(loss)init = tf.global_variables_initializer()sess = tf.Session()sess.run(init)batch_count = 0display_count = 1number_images = 10batch_size = 5number_steps = int(X_train.shape[0]/batch_size)epochs = 0for ep in range(epochs):    for i in range(number_steps):        batch_X, batch_Y = next_batch(batch_size, batch_count)        batch_X_prep = preprocess_batch(batch_X)        batch_count += 1        feed_dict = {X: batch_X_prep, Y: batch_Y, lr: 0.001}        loss_value, _ = sess.run([loss, optimizer], feed_dict=feed_dict)        print('Epoch:', str(ep), 'step:', str(i) + " training loss:", str(loss_value))    batch_count = 0ix = 0 #randomtest_image = X_test[ix]test_image_prep = preprocess_batch(test_image)test_image_prep = np.expand_dims(test_image_prep, axis=0)test_data = {X:test_image_prep}test_mask = sess.run([sigmoid],feed_dict=test_data)test_mask = np.squeeze(test_mask)test_mask = (test_mask*255).astype(np.uint8)f = plt.figure(figsize=(10,10))h_st = (IMG_HEIGHT - MASK_HEIGHT) // 2h_fin = MASK_HEIGHT + h_stw_st = (IMG_WIDTH - MASK_WIDTH) // 2w_fin = MASK_WIDTH + w_stplt.imshow(np.squeeze(test_image)[h_st:h_fin, w_st:w_fin], cmap='gray')plt.imshow(test_mask, alpha=0.2);plt.show()